{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run this first to see the output prediction based on pre-trained data.\n",
    "\n",
    "Note: Choose from {'A': 'a', 'B': 'b', 'C': 'c', 'D':'d', 'E':'e', 'F':'f', 'G':'g', 'H':'h', 'K':'k', 'L':'l', 'Y':'y',  'V':'v'}\n",
    "\n",
    "Code can be altered to do prediction for remaining alphabets also. I have taken into account only 13 alphabets.\n",
    "\n",
    "alphabets -  J and Z are out of scope.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from trained data\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import operator\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.models import model_from_json\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#get from saved model while training\n",
    "json_file = open(\"saved_model.json\", \"r\")\n",
    "model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"saved_model.h5\")\n",
    "print(\"Model loaded from trained data\")\n",
    "\n",
    "real_time_capture = cv2.VideoCapture(0)\n",
    "\n",
    "#---------------------------self begin-------------------------------------------------\n",
    "#alphabets = {'A': 'a', 'B': 'b', 'C': 'c', 'D':'d', 'E':'e','F':'f','G':'g','H':'h','K':'k','L':'l','Y':'y', 'V':'v'}\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    _, frame = real_time_capture.read()\n",
    "    # Simulating mirror image\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    image = cv2.imread('amer_sign2.png')\n",
    "    cv2.imshow(\"sign Language\", image)\n",
    "#---------------------------self end-------------------------------------------------\n",
    "    \n",
    "#---------------------------Source code begin-------------------------------------\n",
    "    #region of interest coordinates\n",
    "    x1 = int(0.5*frame.shape[1])\n",
    "    y1 = 10\n",
    "    x2 = frame.shape[1]-10\n",
    "    y2 = int(0.5*frame.shape[1])\n",
    "    #create ROI rectangle\n",
    "    cv2.rectangle(frame, (x1-1, y1-1), (x2+1, y2+1), (255,0,0) ,1)\n",
    "    # Extracting the ROI\n",
    "    roi = frame[y1+50:y2+50, x1:x2]\n",
    "    roi = cv2.resize(roi, (64, 64)) \n",
    "    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    _, test_image = cv2.threshold(roi, 120, 255, cv2.THRESH_BINARY)\n",
    "    cv2.imshow(\"test\", test_image)\n",
    "    # Batch of 1\n",
    "    result = loaded_model.predict(test_image.reshape(1, 64, 64, 1))\n",
    "    \n",
    "    #----------------------self modified code------------------------------\n",
    "    \n",
    "    ASL_predit = {'A': result[0][0], \n",
    "                  'B': result[0][1], \n",
    "                  'C': result[0][2],\n",
    "                  'D': result[0][3],\n",
    "                  'E': result[0][4], \n",
    "                  'F': result[0][5], \n",
    "                  'G': result[0][6],\n",
    "                  'H': result[0][7],\n",
    "                  'K': result[0][8], \n",
    "                  'L': result[0][9], \n",
    "                  'Y': result[0][11],\n",
    "                  'V': result[0][10]\n",
    "                 }\n",
    "    # perform sorting depending on best predited output\n",
    "    ASL_predit = sorted(ASL_predit.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    #view the output\n",
    "    cv2.putText(frame, ASL_predit[0][0], (10, 200), cv2.FONT_HERSHEY_TRIPLEX, 7, (0,0,255), 2)    \n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    \n",
    "    \n",
    "    Key_int = cv2.waitKey(10)\n",
    "    if Key_int & 0xFF == 27: # esc key\n",
    "        break\n",
    "        \n",
    "real_time_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
